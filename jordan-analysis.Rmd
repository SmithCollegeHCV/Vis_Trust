---
title: "Trust Analysis 2024"
author: "Jordan"
date: "2023-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggplot2)
library(tree)
library(dplyr)
library(rpart.plot)
library(MASS)
library(caret)
library(ztable)
library(GGally)
library(tidyr)
select <- dplyr::select
```

# General Cleaning and Statistical Calculations:

```{r}
trust_2023_raw_data <- read_csv("trust_2023_raw_data.csv") %>%
  mutate(response = factor(response, order = TRUE, 
                           levels = c("Strongly Disagree", "Disagree", "Nor", "Agree", "Strongly Agree")),
         likertscale = factor(likertscale, ordered = TRUE),
         category = factor(category, levels = c("I", "N", "G", "S"), 
                           labels = c("Infographic", "News", "Government", "Scientific")))
```
## Sources
```{r}
trust_2023_raw_data %>%
  select(category, source, image_new) %>%
  unique() %>%
  group_by(category, source) %>%
  summarise(n = n())
```

```{r}
category_data <- trust_2023_raw_data %>%
  select(c(image_new, category, vistype, starts_with("attr"))) %>%
  unique()
```

```{r}
category_prelim_tree <- rpart(category ~.-image_new , data = category_data, method="class", minsplit = 8)
```

```{r}
rpart.plot(category_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```
## Descriminant analysis
```{r}
#use 80% of dataset as training set and 20% as test set 
train <- category_data %>% dplyr::sample_frac(0.70)
test  <- dplyr::anti_join(category_data, train, by = 'image_new')
train <- train %>% select(-image_new)
text <- test %>% select(-image_new)
lda_category <- lda(category ~. , data = train)
```

```{r}
lda_category
```


```{r}
predictions_LDA = data.frame(predict(lda_category, test))

preds <- cbind(test, predictions_LDA) 


# Confusion Matrix
cf <- caret::confusionMatrix(data=preds$class,
                     reference=test$category)

print(cf)

```

# Believe
## Are there some stimuli that got a wide range or responses?
```{r}
trust_2023_raw_data %>%
  filter(name == "I believe the visualization shows real data.") %>%
  group_by(image_new, response) %>%
  summarise(n= n()) %>%
  arrange(response) %>%
  pivot_wider(names_from = response, values_from = n, values_fill = 0) %>%
  rowwise() %>%
  mutate(total_uses = sum(`Strongly Disagree`, `Disagree`, `Nor`, `Agree`, `Strongly Agree`)) %>%
  filter(total_uses > 1) %>%
  arrange(desc(total_uses))
```

## (balanced sampling, n = 125 per group)
Note: remember to drop session_id, etc. or you'll be waiting foreverrrrrr...
```{r}
believe_data <- trust_2023_raw_data %>%
  filter(name == "I believe the visualization shows real data.") %>%
  group_by(likertscale) %>%
  sample_n(125) %>%
  ungroup() %>%
  #mutate(age_cat = cut(age, breaks = c(-Inf,35,50,Inf), labels = c("Under 35", "36-49", "Over 50"))) %>%
  select(-c(...1, name, session_id, image, subfolder, category, likertscale, time,
            starts_with("title"), starts_with("mem"), question_type, cluster, source))
```

```{r}
believe_prelim_tree <- rpart(response ~.-image_new , data = believe_data, method="class", minsplit = 4)
```

```{r}
rpart.plot(believe_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```
## Next steps

#. Label original believe_data with leaf node each observation falls in (maybe a `join(...)` with `predict(...)`?)
#. `group_by` leaf node
#. Select `unique()` images
#. Make some kind of collage so we can look for visual trends
#. Original images can be found at: https://people.csail.mit.edu/zoya/VisThumbnails/fullsize/

```{r}
believe_pred = predict(believe_prelim_tree, believe_data, type = "class")

table(believe_pred, believe_data$response)
```
## Predicted vs. true
```{r}
believe_data_with_pred <- cbind(believe_data, pred = believe_pred) %>%
  mutate(pred = factor(pred, order = TRUE, 
                           levels = c("Strongly Disagree", "Disagree", "Nor", "Agree", "Strongly Agree")))
```  

## Are there some stimuli that got a wide range or responses?
```{r}
believe_data_with_pred %>%
  group_by(image_new, response) %>%
  summarise(n= n()) %>%
  arrange(response) %>%
  pivot_wider(names_from = response, values_from = n, values_fill = 0) %>%
  rowwise() %>%
  mutate(total_uses = sum(`Strongly Disagree`, `Disagree`, `Nor`, `Agree`, `Strongly Agree`)) %>%
  filter(total_uses > 1) %>%
  arrange(desc(total_uses))
```

## Images with largest errors
```{r}
believe_data_with_pred %>%
  group_by(image_new, response) %>%
  summarise(n= n(),
            pred = pred) %>%
  mutate(error = as.numeric(response) - as.numeric(pred)) %>%
  filter(abs(error) > 2) %>%
  arrange(image_new, desc(n))
```


# balanced sampling for strongly agree and disagree:

In the analysis below, we are using decision trees to determine which individual characteristic and visualization attributes influence whether people strongly trust or distrust that visualization for all five dimensions of trust

## Belief:


```{r}
strongly_believe_data <- trust_2023_raw_data %>%
  filter(name == "I believe the visualization shows real data." & (response == "Strongly Agree" | response == "Strongly Disagree")) %>%
  group_by(likertscale) %>%
  sample_n(125) %>%
  ungroup() %>%
  select(-c(...1, name, session_id, image, subfolder, category, likertscale, time,
            starts_with("title"), starts_with("mem"), question_type, cluster, source))
```


```{r}
strong_belief_prelim_tree <- rpart(response ~.-image_new , data = strongly_believe_data, method="class")
```

```{r}
rpart.plot(strong_belief_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```

##Clarity:

```{r}
strongly_clear_data <- trust_2023_raw_data %>%
  filter(name == "I understand what this visualization is trying to tell me." & (response == "Strongly Agree" | response == "Strongly Disagree")) %>%
  group_by(likertscale) %>%
  sample_n(125) %>%
  ungroup() %>%
  select(-c(...1, name, session_id, image, subfolder, category, likertscale, time,
            starts_with("title"), starts_with("mem"), question_type, cluster, source))
```


```{r}
strong_clarity_prelim_tree <- rpart(response ~.-image_new , data = strongly_clear_data, method="class")
```

```{r}
rpart.plot(strong_clarity_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```

##Reliability:

```{r}
strongly_reliable_data <- trust_2023_raw_data %>%
  filter(name == "I would rely on the facts in this Visualization." & (response == "Strongly Agree" | response == "Strongly Disagree")) %>%
  group_by(likertscale) %>%
  sample_n(125) %>%
  ungroup() %>%
  select(-c(...1, name, session_id, image, subfolder, category, likertscale, time,
            starts_with("title"), starts_with("mem"), question_type, cluster, source)) 
```


```{r}
strong_reliability_prelim_tree <- rpart(response ~.-image_new , data = strongly_reliable_data, method="class")
```

```{r}
rpart.plot(strong_reliability_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```

##Familiarity

```{r}
strongly_familiar_data <- trust_2023_raw_data %>%
  filter(name == "I am familiar with the topic or data this visualization presents." & (response == "Strongly Agree" | response == "Strongly Disagree")) %>%
  group_by(likertscale)%>%
  sample_n(125) %>%
  ungroup() %>%
  select(-c(...1, name, session_id, image, subfolder, category, likertscale, time,
            starts_with("title"), starts_with("mem"), question_type, cluster, source))
```


```{r}
strong_familiar_prelim_tree <- rpart(response ~.-image_new , data = strongly_familiar_data, method="class")
```

```{r}
rpart.plot(strong_familiar_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```

##Confidence:


```{r}
strong_confidence_data <- trust_2023_raw_data %>%
  filter(name == "I would feel confident using the information to make a decision." & (response == "Strongly Agree" | response == "Strongly Disagree")) %>%
  group_by(likertscale) %>%
  sample_n(125) %>%
  ungroup() %>%
  select(-c(...1, name, session_id, image, subfolder, category, likertscale, time,
            starts_with("title"), starts_with("mem"), question_type, cluster, source))
```


```{r}
strong_confidence_prelim_tree <- rpart(response ~.-image_new , data = strong_confidence_data, method="class")
```

```{r}
rpart.plot(strong_confidence_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```

# seperate images based on deviation from the usual:
```{r}
trust_placement <- trust_2023_raw_data %>%
  group_by(name, image_new, response) %>%
  summarise(n = n()) %>%
  arrange(name, response) %>%
  pivot_wider(names_from = response, values_from = n, values_fill = 0) %>%
  mutate(
    total_responses = `Strongly Disagree` + `Disagree` + `Nor` + `Agree` + `Strongly Agree`,
    agreement_mean = (2 * `Strongly Agree` + 1 * `Agree` + 0 * `Nor` - 1 * `Disagree` - 2 * `Strongly Disagree`) / total_responses
  ) %>%
  ungroup() %>%
  group_by(name) %>%
  mutate(
    overall_mean = mean(agreement_mean, na.rm = TRUE),
    overall_sd = sd(agreement_mean, na.rm = TRUE),
    agreement_level = case_when(
      agreement_mean > overall_mean + overall_sd ~ "higher",
      agreement_mean < overall_mean - overall_sd ~ "lower",
      TRUE ~ "avg"
    )
  ) %>%
  select(name, image_new, agreement_level) %>%
  mutate(
    name = case_when(
      name == "I am familiar with the topic or data this visualization presents." ~ "Familiarity",
      name == "I believe the visualization shows real data." ~ "Credibility",
      name == "I understand what this visualization is trying to tell me." ~ "Clarity",
      name == "I would rely on the facts in this Visualization." ~ "Reliability",
      name == "I would feel confident using the information to make a decision." ~ "Confidence",
      TRUE ~ name
    )
  ) %>%
  pivot_wider(names_from = name, values_from = agreement_level) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(
    General = case_when(
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) == "lower") >= 2 &
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) %in% c("lower", "avg")) == 5 ~ "lower",
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) == "higher") >= 2 &
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) %in% c("higher", "avg")) == 5 ~ "higher",
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) == "avg") >= 4 ~ "avg",
      TRUE ~ "mixed"
    )
  ) %>%
  select(image_new, General, Familiarity, Credibility, Clarity, Confidence, Reliability)
```

There is a lack of consistent patterns where trust dimensions exhibit opposing trends. The trust dimensions tend to move collectively, either increasing or decreasing. When one dimension is higher, others are divided between 'average' and 'higher.' Conversely, if one dimension is lower, the remaining dimensions tend to be split between 'average' and 'lower.' Exceptions exist where 2 to 3 dimensions may be higher, one lower, and the rest average, or vice versa.

```{r}
trust_placement_percentages <- trust_placement %>%
  group_by(General) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  mutate(percentage = count / sum(count) * 100)
trust_placement_percentages

```

# attr diff
```{r}
merged_vis <- trust_2023_raw_data %>%
  left_join(trust_placement, by = "image_new") %>%
  group_by(image_new) %>%
    select(image_new, vistype, General, category, `attr: data-ink ratio`,
         `attr: # distinct colors`, `attr: black&white`, 
         `attr: visual density`, `attr: human recognizable object`, 
         `attr: human depiction`)%>%

   slice(1)  
merged_vis


```


```{r}
vis_attr_prelim_tree <- rpart(General ~.-image_new -category, data = merged_vis, method="class", minsplit = 8)
```

```{r}
rpart.plot(vis_attr_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```

# individual diff

```{r}
individual_averages <- trust_2023_raw_data %>%
  mutate(
    response_numerical = case_when(
      response == "Strongly Disagree" ~ -2,
      response == "Disagree" ~ -1,
      response == "Nor" ~ 0,
      response == "Agree" ~ 1,
      response == "Strongly Agree" ~ 2,
      TRUE ~ NA_real_
    )
  ) %>%
  group_by(name, session_id) %>%
  summarise(
    agreement_mean = mean(response_numerical, na.rm = TRUE),
    agreement_sd = sd(response_numerical, na.rm = TRUE)
  ) %>%
  mutate(
    name = case_when(
      name == "I am familiar with the topic or data this visualization presents." ~ "Familiarity",
      name == "I believe the visualization shows real data." ~ "Credibility",
      name == "I understand what this visualization is trying to tell me." ~ "Clarity",
      name == "I would rely on the facts in this Visualization." ~ "Reliability",
      name == "I would feel confident using the information to make a decision." ~ "Confidence",
      TRUE ~ name
    )
  )
```

```{r}
individual_averages_table<- individual_averages %>%
  pivot_wider(names_from = name, values_from = c(agreement_mean, agreement_sd))%>%
  mutate(
    Familiarity = paste(round(agreement_mean_Familiarity, 2), "/", round(agreement_sd_Familiarity, 2)),
    Credibility = paste(round(agreement_mean_Credibility, 2), "/", round(agreement_sd_Credibility, 2)),
    Clarity = paste(round(agreement_mean_Clarity, 2), "/", round(agreement_sd_Clarity, 2)),
    Reliability = paste(round(agreement_mean_Reliability, 2), "/", round(agreement_sd_Reliability, 2)),
    Confidence = paste(round(agreement_mean_Confidence, 2), "/", round(agreement_sd_Confidence, 2))
  ) %>%
  select(session_id, Familiarity, Credibility, Clarity, Confidence, Reliability)
```



```{r}
individual_placement <- individual_averages %>%
  ungroup() %>%
  group_by(name) %>%
  mutate(
    overall_mean = mean(agreement_mean, na.rm = TRUE),
    overall_sd = sd(agreement_mean, na.rm = TRUE),
    agreement_level = case_when(
      agreement_mean > overall_mean + overall_sd ~ "higher",
      agreement_mean < overall_mean - overall_sd ~ "lower",
      TRUE ~ "avg"
    )
  ) %>%
  select(name, session_id, agreement_level) %>%
  pivot_wider(names_from = name, values_from = agreement_level) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(
    General = case_when(
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) == "lower") >= 2 &
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) %in% c("lower", "avg")) == 5 ~ "lower",
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) == "higher") >= 2 &
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) %in% c("higher", "avg")) == 5 ~ "higher",
      sum(c(Familiarity, Credibility, Clarity, Confidence, Reliability) == "avg") >= 4 ~ "avg",
      TRUE ~ "mixed"
    )
  ) %>%
  select(session_id, General, Familiarity, Credibility, Clarity, Confidence, Reliability)

```

```{r}
merged_individual <- trust_2023_raw_data %>%
  left_join(individual_placement, by = "session_id") %>%
  group_by(session_id) %>%
  select(session_id, General, age, sex, education, mini_score)%>%
  filter(General %in% c("higher", "lower"))%>%

  slice(1)  
merged_individual

```
```{r}
individual_placement_percentages <- individual_placement %>%
  group_by(General) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  mutate(percentage = count / sum(count) * 100)

individual_placement_percentages

```

```{r}
individual_char_prelim_tree <- rpart(General ~.-session_id, data = merged_individual, method="class", minsplit=4)
```

```{r}
rpart.plot(individual_char_prelim_tree, type = 4, clip.right.labs = FALSE, extra=2)
```

Here we are trying to visualize how higher and lower trust is distributed by visual literacy, sex, and education.

```{r}
education_order <- c("highschool", "associate", "bachelors", "masters", "doctorate")

merged_individual <- merged_individual %>%
  mutate(education = factor(education, levels = education_order))
merged_individual%>%
ggplot(aes(x=age,y=mini_score, color=General))+geom_point()+facet_grid(sex~education)
```

```{r}
merged_individual%>%
  mutate(over_59= age>=59 )%>%
  group_by(sex, over_59,education)%>%
  summarize(n=n())%>%
  pivot_wider(names_from= education, values_from = n)
```


